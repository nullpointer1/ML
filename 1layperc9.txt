import numpy as np

def step_function(x):
    if x >= 0:
        return 1
    else:
        return 0

def perceptron_learning(X, y, lr=0.1, epochs=10):
    weights = np.zeros(X.shape[1])  # Initialize weights as 0
    bias = 0  # Bias term

    print("Epoch | Weights       | Bias")
    print("-----------------------------")
    
    for epoch in range(epochs):
        for i in range(len(X)):
            weighted_sum = np.dot(X[i], weights) + bias
            y_pred = step_function(weighted_sum)

            # Weight update rule
            error = y[i] - y_pred
            weights += lr * error * X[i]
            bias += lr * error

        # Print weights and bias after each epoch
        print(f"{epoch + 1:<5} | {weights} | {bias}")

    return weights, bias


X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Inputs
y = np.array([0, 1, 1, 1])                      # OR gate outputs

weights, bias = perceptron_learning(X, y)

print("\nTesting Perceptron on OR Gate:")
for x in X:
    output = step_function(np.dot(x, weights) + bias)
    print(f"Input: {x}, Output: {output}")
